{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Tfhq9Cc2uEfd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow import keras \n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report, balanced_accuracy_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wAJIdZ9euEfp"
   },
   "outputs": [],
   "source": [
    "def saveModel(model, filename):\n",
    "    model.save(filename)\n",
    "\n",
    "def loadModel(filename):\n",
    "    model = joblib.load(filename)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jOxsJWu6uEgC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/[CLEANED]kepler-data.csv\")\n",
    "df.drop(columns = [\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WhX_TnO_uEgJ"
   },
   "outputs": [],
   "source": [
    "ALL_COLUMNS = df.columns\n",
    "ERROR_COLUMNS = [col for col in ALL_COLUMNS if \"err\" in col]\n",
    "EXCLUDE = [\"rowid\", \"kepid\", \"kepoi_name\", \"koi_score\", \"koi_disposition\", \"koi_pdisposition\", \"koi_tce_delivname\", \"koi_tce_plnt_num\"] #+ ERROR_COLUMNS\n",
    "TO_USE = list(set(ALL_COLUMNS) - set(EXCLUDE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "4XOHBGoRuEgP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset_df = df[df[\"koi_disposition\"] != \"CANDIDATE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Wres19PvuEgW"
   },
   "outputs": [],
   "source": [
    "X = subset_df[TO_USE].values\n",
    "y = subset_df[\"koi_disposition\"].apply(lambda x: x=='CONFIRMED').astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qzlI6_9iuEgc"
   },
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)\n",
    "X = PCA(n_components=30).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "O-fgCEufuEgh"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    model = Sequential([\n",
    "                    Dense(256, activation = 'relu'),\n",
    "                    Dense(128, activation = 'relu'),\n",
    "                    Dense(128, activation = 'relu'),\n",
    "                    Dense(1, activation = 'sigmoid')\n",
    "                   ])\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "4KBWWHO6uEg7"
   },
   "outputs": [],
   "source": [
    "def performance(test, pred):\n",
    "    conf_matrix = confusion_matrix(test, pred)\n",
    "    f1 = f1_score(test, pred)\n",
    "    report = classification_report(test, pred)\n",
    "    accuracy = balanced_accuracy_score(test, pred)\n",
    "    kappa = cohen_kappa_score(test, pred)\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"Kappa Score: {kappa}\")\n",
    "    print(f\"Accuracy Score: {accuracy}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "q4jU9ktQuEgl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainEvaluate(model, fold, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train, epochs=20, verbose=0)\n",
    "    pred = model.predict(X_test)\n",
    "    pred = pred >= 0.5\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    print(f\"F1 Score in fold {fold} = {f1}\")\n",
    "    return f1\n",
    "\n",
    "\n",
    "def crossValidation(K=10):\n",
    "    kFold = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "    f1_scores = list()\n",
    "    k_ctr = 1\n",
    "    for train, test in kFold.split(X, y):\n",
    "        model = None\n",
    "        model = createModel()\n",
    "        current_f1 = trainEvaluate(model, k_ctr, X[train], y[train], X[test], y[test])\n",
    "        f1_scores.append(current_f1)\n",
    "        k_ctr+=1\n",
    "    print(f\"Average {K}-Fold F1 Score = {np.mean(f1_scores)}\\n\")\n",
    "    \n",
    "    k_ctr = 1\n",
    "    kFold = StratifiedKFold(n_splits=K, shuffle=True, random_state=0)\n",
    "    f1_scores = list()\n",
    "    for train, test in kFold.split(X, y):\n",
    "        model = None\n",
    "        model = createModel()\n",
    "        current_f1 = trainEvaluate(model, k_ctr, X[train], y[train], X[test], y[test])\n",
    "        f1_scores.append(current_f1)\n",
    "        k_ctr+=1\n",
    "    print(f\"Average Stratified {K}-Fold F1 Score = {np.mean(f1_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "YB2ej2IGuEgr",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score in fold 1 = 0.979498861047836\n",
      "F1 Score in fold 2 = 0.985981308411215\n",
      "F1 Score in fold 3 = 0.9755011135857461\n",
      "F1 Score in fold 4 = 0.9756097560975608\n",
      "F1 Score in fold 5 = 0.9837587006960558\n",
      "F1 Score in fold 6 = 0.9794238683127573\n",
      "F1 Score in fold 7 = 0.9854469854469856\n",
      "F1 Score in fold 8 = 0.9892933618843683\n",
      "F1 Score in fold 9 = 0.9897330595482547\n",
      "F1 Score in fold 10 = 0.9841986455981941\n",
      "Average 10-Fold F1 Score = 0.9828445660628976\n",
      "\n",
      "F1 Score in fold 1 = 0.9827586206896551\n",
      "F1 Score in fold 2 = 0.989010989010989\n",
      "F1 Score in fold 3 = 0.9730941704035875\n",
      "F1 Score in fold 4 = 0.973568281938326\n",
      "F1 Score in fold 5 = 0.9823788546255506\n",
      "F1 Score in fold 6 = 0.9847494553376905\n",
      "F1 Score in fold 7 = 0.9956140350877193\n",
      "F1 Score in fold 8 = 0.9868995633187773\n",
      "F1 Score in fold 9 = 0.982532751091703\n",
      "F1 Score in fold 10 = 0.9823008849557523\n",
      "Average Stratified 10-Fold F1 Score = 0.9832907606459751\n"
     ]
    }
   ],
   "source": [
    "crossValidation(K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel()\n",
    "model.fit(X_train, y_train, epochs=20, verbose=0)\n",
    "pred = model.predict(X_test)\n",
    "pred = pred >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EMl1avnuEhB",
    "outputId": "6bb1a996-92cf-42fc-9626-93bdc7ac36ab",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9880159786950733\n",
      "Kappa Score: 0.9821684111803456\n",
      "Accuracy Score: 0.9894369597759428\n",
      "Confusion Matrix:\n",
      "[[1530    4]\n",
      " [  14  742]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1534\n",
      "           1       0.99      0.98      0.99       756\n",
      "\n",
      "    accuracy                           0.99      2290\n",
      "   macro avg       0.99      0.99      0.99      2290\n",
      "weighted avg       0.99      0.99      0.99      2290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performance(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "n2TFkQXGuEhF"
   },
   "outputs": [],
   "source": [
    "saveModel(model, \"../model/nn-model-error.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
