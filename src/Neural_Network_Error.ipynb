{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Tfhq9Cc2uEfd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow import keras \n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report, balanced_accuracy_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wAJIdZ9euEfp"
   },
   "outputs": [],
   "source": [
    "def saveModel(model, filename):\n",
    "    model.save(filename)\n",
    "\n",
    "def loadModel(filename):\n",
    "    model = joblib.load(filename)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jOxsJWu6uEgC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/[CLEANED]kepler-data.csv\")\n",
    "df.drop(columns = [\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WhX_TnO_uEgJ"
   },
   "outputs": [],
   "source": [
    "ALL_COLUMNS = df.columns\n",
    "ERROR_COLUMNS = [col for col in ALL_COLUMNS if \"err\" in col]\n",
    "EXCLUDE = [\"rowid\", \"kepid\", \"kepoi_name\", \"koi_score\", \"koi_disposition\", \"koi_pdisposition\", \"koi_tce_delivname\", \"koi_tce_plnt_num\"] #+ ERROR_COLUMNS\n",
    "TO_USE = list(set(ALL_COLUMNS) - set(EXCLUDE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4XOHBGoRuEgP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset_df = df[df[\"koi_disposition\"] != \"CANDIDATE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Wres19PvuEgW"
   },
   "outputs": [],
   "source": [
    "X = subset_df[TO_USE].values\n",
    "y = subset_df[\"koi_disposition\"].apply(lambda x: x=='CONFIRMED').astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qzlI6_9iuEgc"
   },
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)\n",
    "X = PCA(n_components=30).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O-fgCEufuEgh"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    model = Sequential([\n",
    "                    Dense(256, activation = 'relu'),\n",
    "                    Dense(128, activation = 'relu'),\n",
    "                    Dense(128, activation = 'relu'),\n",
    "                    Dense(1, activation = 'sigmoid')\n",
    "                   ])\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4KBWWHO6uEg7"
   },
   "outputs": [],
   "source": [
    "def performance(test, pred):\n",
    "    conf_matrix = confusion_matrix(test, pred)\n",
    "    f1 = f1_score(test, pred)\n",
    "    report = classification_report(test, pred)\n",
    "    accuracy = balanced_accuracy_score(test, pred)\n",
    "    kappa = cohen_kappa_score(test, pred)\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"Kappa Score: {kappa}\")\n",
    "    print(f\"Accuracy Score: {accuracy}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "q4jU9ktQuEgl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainEvaluate(model, fold, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train, epochs=20, verbose=0)\n",
    "    pred = model.predict(X_test)\n",
    "    pred = pred >= 0.5\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    print(f\"F1 Score in fold {fold} = {f1}\")\n",
    "    return f1\n",
    "\n",
    "\n",
    "def crossValidation(K=10):\n",
    "    kFold = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "    f1_scores = list()\n",
    "    k_ctr = 1\n",
    "    for train, test in kFold.split(X, y):\n",
    "        model = None\n",
    "        model = createModel()\n",
    "        current_f1 = trainEvaluate(model, k_ctr, X[train], y[train], X[test], y[test])\n",
    "        f1_scores.append(current_f1)\n",
    "        k_ctr+=1\n",
    "    print(f\"Average {K}-Fold F1 Score = {np.mean(f1_scores)}\\n\")\n",
    "    \n",
    "    k_ctr = 1\n",
    "    kFold = StratifiedKFold(n_splits=K, shuffle=True, random_state=0)\n",
    "    f1_scores = list()\n",
    "    for train, test in kFold.split(X, y):\n",
    "        model = None\n",
    "        model = createModel()\n",
    "        current_f1 = trainEvaluate(model, k_ctr, X[train], y[train], X[test], y[test])\n",
    "        f1_scores.append(current_f1)\n",
    "        k_ctr+=1\n",
    "    print(f\"Average Stratified {K}-Fold F1 Score = {np.mean(f1_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YB2ej2IGuEgr",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score in fold 1 = 0.9772727272727272\n",
      "F1 Score in fold 2 = 0.985981308411215\n",
      "F1 Score in fold 3 = 0.9799554565701559\n",
      "F1 Score in fold 4 = 0.9777777777777777\n",
      "F1 Score in fold 5 = 0.9837587006960558\n",
      "F1 Score in fold 6 = 0.9917355371900827\n",
      "F1 Score in fold 7 = 0.9876033057851239\n",
      "F1 Score in fold 8 = 0.9850746268656715\n",
      "F1 Score in fold 9 = 0.9835390946502057\n",
      "F1 Score in fold 10 = 0.9864864864864865\n",
      "Average 10-Fold F1 Score = 0.9839185021705502\n",
      "\n",
      "F1 Score in fold 1 = 0.9848156182212582\n",
      "F1 Score in fold 2 = 0.9890590809628009\n",
      "F1 Score in fold 3 = 0.9623059866962307\n",
      "F1 Score in fold 4 = 0.9715536105032824\n",
      "F1 Score in fold 5 = 0.9801324503311258\n",
      "F1 Score in fold 6 = 0.9868995633187773\n",
      "F1 Score in fold 7 = 0.9934065934065934\n",
      "F1 Score in fold 8 = 0.9826839826839826\n",
      "F1 Score in fold 9 = 0.9912663755458515\n",
      "F1 Score in fold 10 = 0.9758241758241758\n",
      "Average Stratified 10-Fold F1 Score = 0.9817947437494079\n"
     ]
    }
   ],
   "source": [
    "crossValidation(K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel()\n",
    "model.fit(X_train, y_train, epochs=20, verbose=0)\n",
    "pred = model.predict(X_test)\n",
    "pred = pred >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EMl1avnuEhB",
    "outputId": "6bb1a996-92cf-42fc-9626-93bdc7ac36ab",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9867021276595744\n",
      "Kappa Score: 0.9802004509801209\n",
      "Accuracy Score: 0.9887850692935438\n",
      "Confusion Matrix:\n",
      "[[1528    6]\n",
      " [  14  742]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1534\n",
      "           1       0.99  